{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "29BQtFJxuJO8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VvrDCVchvb8k"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import gdown\n",
    "\n",
    "# # Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Replace with your file ID from Google Drive\n",
    "# file_id = \"13t4sY57Pnd8ENG4ENU3YYFUTGXzJX4rf\"\n",
    "\n",
    "# # Specify the destination path within your Google Drive\n",
    "# destination = '/content/drive/MyDrive/dataset.csv'  # Change this path as needed\n",
    "\n",
    "# # Download the file from Google Drive\n",
    "# gdown.download(f\"https://drive.google.com/uc?id={file_id}\", destination, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skOCIw6z_3Bx",
    "outputId": "84e528dc-3bf1-43fe-bde6-b89851481a25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recipe Dataset',\n",
       " 'Colab Notebooks',\n",
       " 'dataset.zip',\n",
       " 'dataset.csv',\n",
       " 'datasets',\n",
       " 'food_model.h5',\n",
       " 'food_model_float32.h5',\n",
       " 'dataset.csv5c6dtdqt.part',\n",
       " 'yolov5-master',\n",
       " 'fridge.webp',\n",
       " 'yolov5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the extracted files\n",
    "os.listdir(\"/content/drive/MyDrive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqKRO49hzqyr"
   },
   "source": [
    "recipe dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "a6xR8Pp8_3dh",
    "outputId": "51ebbe3e-99e4-420d-b534-bc341c9492ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4d8f5df4-fa96-445f-bc08-4d666a2ea411\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d8f5df4-fa96-445f-bc08-4d666a2ea411')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4d8f5df4-fa96-445f-bc08-4d666a2ea411 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4d8f5df4-fa96-445f-bc08-4d666a2ea411');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c155b8a2-bf4d-454b-86d8-8cbb4db08990\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c155b8a2-bf4d-454b-86d8-8cbb4db08990')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c155b8a2-bf4d-454b-86d8-8cbb4db08990 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0                  title  \\\n",
       "0           0    No-Bake Nut Cookies   \n",
       "1           1  Jewell Ball'S Chicken   \n",
       "2           2            Creamy Corn   \n",
       "3           3          Chicken Funny   \n",
       "4           4   Reeses Cups(Candy)     \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
       "1  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
       "3  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
       "4  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1  [\"Place chipped beef on bottom of baking dish....   \n",
       "2  [\"In a slow cooker, combine all ingredients. C...   \n",
       "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4  [\"Combine first four ingredients and press in ...   \n",
       "\n",
       "                                              link    source  \\\n",
       "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
       "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
       "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
       "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
       "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
       "\n",
       "                                                 NER  \n",
       "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
       "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
       "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
       "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
       "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from Google Drive\n",
    "df = pd.read_csv('/content/drive/MyDrive/dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TrAlqSKzCFXA"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# import zipfile\n",
    "\n",
    "# # Download URL for Food-101\n",
    "# url = \"https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
    "# output = \"food-101.tar.gz\"\n",
    "\n",
    "# # Download and extract\n",
    "# gdown.download(url, output, quiet= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GfFR8X97EEXw"
   },
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "\n",
    "# # Path to the downloaded file\n",
    "# tar_file_path = 'food-101.tar.gz'\n",
    "\n",
    "# # Extract the tar.gz file\n",
    "# with tarfile.open(tar_file_path, 'r:gz') as tar:\n",
    "#     tar.extractall(path='/content/drive/MyDrive/datasets/food101')  # Change the path if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2znZ5TZzzKd"
   },
   "source": [
    "foof 101 dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb2bijo0Kmam",
    "outputId": "6e425242-4be5-4862-9d45-37f623c27a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food-101 dataset extracted to: /content/drive/MyDrive/datasets/food101/food-101\n",
      "Contents of the extracted folder: ['images', 'meta', 'license_agreement.txt', 'README.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path where you extracted the dataset\n",
    "extracted_path = '/content/drive/MyDrive/datasets/food101/food-101'  # Change this to your desired path\n",
    "\n",
    "# Verify the extraction of Food-101\n",
    "print(\"Food-101 dataset extracted to:\", extracted_path)\n",
    "print(\"Contents of the extracted folder:\", os.listdir(extracted_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtsuUPke1BOA"
   },
   "source": [
    "data preprocessing, including rescaling and splitting the dataset into training and validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_rzLffqrD3qB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "df['ingredients'] = df['ingredients'].apply(lambda x: x.lower().strip())\n",
    "def extract_ingredients(ingredient_str):\n",
    "    return ingredient_str.split(',')\n",
    "df['ingredient_list'] = df['ingredients'].apply(extract_ingredients)\n",
    "food_images_path = os.path.join(extracted_path, 'images')\n",
    "food_classes = os.listdir(food_images_path)\n",
    "\n",
    "# Image Data Generator\n",
    "image_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `X` contains images and `y` contains labels.\n",
    "# Split into 90% training+validation and 10% testing\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Further split the remaining 90% into 80% training and 10% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, random_state=42)  # 0.1111 ensures ~10% of total\n",
    "\n",
    "print(f\"Training data: {len(X_train)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "print(f\"Testing data: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Generators\n",
    "image_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = image_gen.flow(X_train, y_train, batch_size=32)\n",
    "val_gen = image_gen.flow(X_val, y_val, batch_size=32)\n",
    "\n",
    "# Testing (scaled manually since ImageDataGenerator is not applied)\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVmSmmANKwrZ",
    "outputId": "30f1c2df-04b3-4e4c-bca2-2291d1f69fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80800 images belonging to 101 classes.\n",
      "Found 20200 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = image_gen.flow_from_directory(\n",
    "    food_images_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,  # Reduced batch size\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = image_gen.flow_from_directory(\n",
    "    food_images_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,  # Reduced batch size\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azrlKuS41NL4"
   },
   "source": [
    "Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBxlnAdQK-V6",
    "outputId": "e616ed85-6e34-4c1a-f0e3-0794730bff45"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.0138 - loss: 4.9402 - val_accuracy: 0.0625 - val_loss: 4.3666\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.0800 - loss: 4.2886 - val_accuracy: 0.1250 - val_loss: 4.0366\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.1484 - loss: 3.8696 - val_accuracy: 0.2125 - val_loss: 3.4730\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.1617 - loss: 3.6121 - val_accuracy: 0.2500 - val_loss: 3.3046\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.2387 - loss: 3.3956 - val_accuracy: 0.2937 - val_loss: 3.0292\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.2595 - loss: 3.1715 - val_accuracy: 0.2750 - val_loss: 2.9913\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.2861 - loss: 2.9452 - val_accuracy: 0.3063 - val_loss: 2.9827\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.3495 - loss: 2.8371 - val_accuracy: 0.2812 - val_loss: 2.8861\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.2892 - loss: 2.7822 - val_accuracy: 0.3250 - val_loss: 2.6702\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.3207 - loss: 2.7053 - val_accuracy: 0.2562 - val_loss: 2.9351\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model and freeze its layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  # Freeze the pre-trained model's layers\n",
    "\n",
    "# Build the final model\n",
    "model = models.Sequential([\n",
    "    base_model,  # Pre-trained MobileNetV2 as feature extractor\n",
    "    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce spatial dimensions\n",
    "    layers.Dense(256, activation='relu'),  # Dense layer for higher-level features\n",
    "    layers.Dense(len(food_classes), activation='softmax')  # Output layer with number of food classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model using the ImageDataGenerator's train and validation generators\n",
    "history = model.fit(\n",
    "    train_gen,  # Training data generator\n",
    "    epochs=10,  # Number of epochs\n",
    "    validation_data=val_gen,  # Validation data generator\n",
    "    callbacks=[early_stopping],  # Early stopping to avoid overfitting\n",
    "    steps_per_epoch=50,  # Limit steps per epoch for faster training\n",
    "    validation_steps=10  # Limit validation steps to speed up the process\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iM8m5UnV1M3T"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVFLoB7cMg3P",
    "outputId": "bbd29fde-e6c3-4d4b-f4bc-718a42ca42d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kktJUOlHNv1T",
    "outputId": "8873a296-d126-4d07-a4b6-1ca72cfa075c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/drive/MyDrive/yolov5'...\n",
      "remote: Enumerating objects: 17075, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 17075 (delta 19), reused 7 (delta 7), pack-reused 17049 (from 2)\u001b[K\n",
      "Receiving objects: 100% (17075/17075), 15.68 MiB | 11.27 MiB/s, done.\n",
      "Resolving deltas: 100% (11719/11719), done.\n",
      "Updating files: 100% (146/146), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 /content/drive/MyDrive/yolov5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2y83o25MNzZ8",
    "outputId": "95fbd7a2-bbcb-4005-e960-ed37d4fd059a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.0\n",
      "    Uninstalling matplotlib-3.8.0:\n",
      "      Successfully uninstalled matplotlib-3.8.0\n",
      "Successfully installed matplotlib-3.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch torchvision matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2g63-xMNj0c",
    "outputId": "bbaae930-c02c-4e55-c74e-a0f11852ee2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-12-22 Python-3.10.12 torch-2.5.1+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/yolov5')  # Add YOLOv5 directory to Python path\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load the YOLOv5 model (adjust the model size if needed, 'yolov5s' is the small version)\n",
    "# Providing the 'yolov5' directory as the repo and specifying the model\n",
    "yolov5_model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/yolov5/yolov5s.pt')\n",
    "# or\n",
    "# If you have cloned the repo, then you can directly load from the local directory\n",
    "# yolov5_model = torch.hub.load('/content/drive/MyDrive/yolov5', 'yolov5s', source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JB7wQSTbKNTm"
   },
   "outputs": [],
   "source": [
    "def detect_items_with_yolo(image_path, yolov5_model):\n",
    "    img = cv2.imread(image_path)  # Read image using OpenCV\n",
    "    results = yolov5_model(img)  # Run YOLOv5 detection\n",
    "    results.print()  # Print detection results\n",
    "\n",
    "    # Get detected items and their labels (class names)\n",
    "    detected_items = results.names  # Labels of detected objects\n",
    "    return detected_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TSIFhzayOSqL"
   },
   "outputs": [],
   "source": [
    "def predict_fridge_contents(image_path, model, label_encoder, img_size=(128, 128)):\n",
    "    # Read and resize the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} could not be loaded. Check the path and file.\")\n",
    "    img_resized = cv2.resize(img, img_size)\n",
    "    img_resized = np.expand_dims(img_resized / 255.0, axis=0)  # Normalize and expand dimensions\n",
    "\n",
    "    # Predict the contents\n",
    "    predictions = model.predict(img_resized)\n",
    "    predicted_labels = label_encoder.inverse_transform(np.argsort(predictions[0])[-5:][::-1])  # Top 5 predictions\n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlgrs0C7K60V",
    "outputId": "b752d957-e3a5-4bc0-92f3-827c8c65d6b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "image 1/1: 280x462 2 bottles, 1 bowl\n",
      "Speed: 4.2ms pre-process, 410.6ms inference, 2.2ms NMS per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected food items with YOLOv5: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted food items: ['sashimi' 'pulled_pork_sandwich' 'ice_cream' 'macarons' 'sushi']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# You'll need to fit it to your class labels at some point before using it\n",
    "# Assuming 'food_classes' from your earlier code contains the class labels:\n",
    "label_encoder.fit(food_classes)\n",
    "\n",
    "fridge_image_path = r\"/content/drive/MyDrive/fridge.webp\"\n",
    "\n",
    "# Detect items using YOLOv5\n",
    "detected_items = detect_items_with_yolo(fridge_image_path, yolov5_model)\n",
    "print(f\"Detected food items with YOLOv5: {detected_items}\")\n",
    "\n",
    "# Predict food items using the trained model (e.g., food classification model)\n",
    "detected_food_items = predict_fridge_contents(fridge_image_path, model, label_encoder)  # Now using the created label_encoder\n",
    "print(f\"Predicted food items: {detected_food_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2fJEjv7kRUt"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import gc\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "# Monitor memory usage\n",
    "def monitor_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Available memory: {memory.available / 1024 / 1024} MB\")\n",
    "\n",
    "# Parse ingredient strings into lists\n",
    "def parse_ingredients(ingredient_str):\n",
    "    try:\n",
    "        return ast.literal_eval(ingredient_str)  # Safely evaluate the string to a list\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Suggest recipes based on detected items\n",
    "def suggest_recipes(detected_items, recipes_df):\n",
    "    detected_items = [item.strip().lower() for item in detected_items]  # Clean detected items\n",
    "    suggested_recipes = []\n",
    "\n",
    "    for _, recipe in recipes_df.iterrows():\n",
    "        ingredients = [ingredient.strip().lower() for ingredient in recipe['ingredient_list']]\n",
    "        if all(item in ingredients for item in detected_items):\n",
    "            suggested_recipes.append(recipe['title'])\n",
    "\n",
    "    return suggested_recipes\n",
    "\n",
    "# Process recipes in batches to handle large datasets\n",
    "def process_in_batches(detected_items, df, batch_size=1000):\n",
    "    suggested_recipes_all = []\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        batch = df[start:start + batch_size]\n",
    "        suggested_recipes_batch = suggest_recipes(detected_items, batch)\n",
    "        suggested_recipes_all.extend(suggested_recipes_batch)\n",
    "        del batch\n",
    "        gc.collect()\n",
    "    return suggested_recipes_all\n",
    "\n",
    "# Function to detect items in fridge image using YOLOv5\n",
    "def detect_items_with_yolo(image_path, yolov5_model):\n",
    "    img = cv2.imread(image_path)  # Read image using OpenCV\n",
    "    results = yolov5_model(img)  # Run YOLOv5 detection\n",
    "    detected_items = results.pandas().xyxy[0]['name'].tolist()  # Extract names of detected objects\n",
    "    return detected_items\n",
    "\n",
    "\n",
    "# Load the recipe dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "df['ingredient_list'] = df['ingredients'].apply(parse_ingredients)\n",
    "\n",
    "# Detect items in the fridge\n",
    "detected_items = detect_items_with_yolo(fridge_image_path, yolov5_model)\n",
    "print(f\"Detected items: {detected_items}\")\n",
    "\n",
    "# Suggest recipes based on detected items\n",
    "monitor_memory()\n",
    "suggested_recipes = process_in_batches(detected_items, df)\n",
    "monitor_memory()\n",
    "\n",
    "# Handle cases where no recipes are found\n",
    "if suggested_recipes:\n",
    "    print(f\"Suggested recipes: {suggested_recipes}\")\n",
    "else:\n",
    "    print(\"No matching recipes found for the detected items.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOpBsiwekSTr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
